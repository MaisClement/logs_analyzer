#!/usr/bin/env python3
"""
Script de test automatisÃ© pour valider la robustesse du systÃ¨me
"""

import os
import sys
import json
import sqlite3
from pathlib import Path
from main import LogFlowTracker
from cli import main as cli_main

class TestRunner:
    def __init__(self):
        self.tracker = LogFlowTracker()
        self.test_results = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'details': []
        }
    
    def log_test(self, test_name: str, success: bool, details: str = ""):
        """Enregistre le rÃ©sultat d'un test"""
        self.test_results['total_tests'] += 1
        if success:
            self.test_results['passed_tests'] += 1
            status = "âœ“ PASS"
        else:
            self.test_results['failed_tests'] += 1
            status = "âœ— FAIL"
        
        print(f"{status} - {test_name}")
        if details:
            print(f"     {details}")
        
        self.test_results['details'].append({
            'test_name': test_name,
            'status': 'PASS' if success else 'FAIL',
            'details': details
        })
    
    def test_file_processing(self):
        """Test du traitement des fichiers de logs"""
        print("\n=== Test du traitement des fichiers ===")
        
        test_files = [
            'exemples_logs/traitement_commande.log',
            'exemples_logs/test_complexe.log',
            'exemples_logs/test_stress.log',
            'exemples_logs/test_erreurs.log',
            'exemples_logs/test_concurrent.log'
        ]
        
        for file_path in test_files:
            if Path(file_path).exists():
                try:
                    stats = self.tracker.process_log_file(file_path)
                    success = stats['processed_lines'] > 0
                    details = f"Lignes: {stats['total_lines']}, TraitÃ©es: {stats['processed_lines']}, Ã‰chouÃ©es: {stats['failed_lines']}"
                    self.log_test(f"Fichier {file_path}", success, details)
                except Exception as e:
                    self.log_test(f"Fichier {file_path}", False, f"Erreur: {e}")
            else:
                self.log_test(f"Fichier {file_path}", False, "Fichier non trouvÃ©")
    
    def test_json_processing(self):
        """Test du traitement des logs JSON"""
        print("\n=== Test du traitement JSON ===")
        
        json_files = [
            'exemples_logs/elasticsearch_logs.json',
            'exemples_logs/elasticsearch_complexe.json'
        ]
        
        for file_path in json_files:
            if Path(file_path).exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        json_data = json.load(f)
                    
                    stats = self.tracker.process_json_logs(json_data)
                    success = stats['processed_entries'] > 0
                    details = f"EntrÃ©es: {stats['total_entries']}, TraitÃ©es: {stats['processed_entries']}, Ã‰chouÃ©es: {stats['failed_entries']}"
                    self.log_test(f"JSON {file_path}", success, details)
                except Exception as e:
                    self.log_test(f"JSON {file_path}", False, f"Erreur: {e}")
            else:
                self.log_test(f"JSON {file_path}", False, "Fichier non trouvÃ©")
    
    def test_individual_lines(self):
        """Test du traitement ligne par ligne"""
        print("\n=== Test ligne par ligne ===")
        
        test_lines = [
            # Ligne normale
            ("[2024-01-15 10:30:00] COMMANDE_RECU CMD_TEST_001 client=CLI_TEST articles=[ART_TEST]", True),
            
            # Ligne avec caractÃ¨res spÃ©ciaux
            ("[2024-01-15 10:30:00] COMMANDE_RECU CMD_SPÃ‰CIAL_001 client=CLI_Ã‰MOJI_ğŸ˜€ articles=[ART_ä¸­æ–‡_001]", True),
            
            # Ligne malformÃ©e
            ("Cette ligne n'est pas un log valide", False),
            
            # Ligne avec date invalide
            ("[2024-13-45 25:99:99] COMMANDE_RECU CMD_BAD client=CLI_001 articles=[ART_001]", False),
            
            # Ligne vide
            ("", False),
            
            # Ligne avec donnÃ©es manquantes
            ("[2024-01-15 10:30:00] COMMANDE_RECU  client= articles=[]", False),
        ]
        
        for line, expected_success in test_lines:
            try:
                result = self.tracker.process_log_line(line)
                success = (result == expected_success)
                details = f"Attendu: {'succÃ¨s' if expected_success else 'Ã©chec'}, Obtenu: {'succÃ¨s' if result else 'Ã©chec'}"
                self.log_test(f"Ligne: {line[:50]}...", success, details)
            except Exception as e:
                success = not expected_success  # Si exception et Ã©chec attendu, c'est bon
                details = f"Exception: {e}"
                self.log_test(f"Ligne: {line[:50]}...", success, details)
    
    def test_forced_application(self):
        """Test du forÃ§age d'application"""
        print("\n=== Test forÃ§age d'application ===")
        
        # Test avec application forcÃ©e correcte
        line = "[2024-01-15 10:30:00] COMMANDE_RECU CMD_FORCE_001 client=CLI_001 articles=[ART_001]"
        try:
            result = self.tracker.process_log_line(line, force_application="Frontend")
            self.log_test("ForÃ§age Frontend valide", result, "Application forcÃ©e correctement")
        except Exception as e:
            self.log_test("ForÃ§age Frontend valide", False, f"Erreur: {e}")
        
        # Test avec application forcÃ©e incorrecte
        try:
            result = self.tracker.process_log_line(line, force_application="ApplicationInexistante")
            self.log_test("ForÃ§age application inexistante", not result, "Rejet attendu pour application inexistante")
        except Exception as e:
            self.log_test("ForÃ§age application inexistante", True, "Exception attendue")
    
    def test_cross_references(self):
        """Test des rÃ©fÃ©rences croisÃ©es"""
        print("\n=== Test des rÃ©fÃ©rences croisÃ©es ===")
        
        # CrÃ©er une sÃ©quence de logs avec rÃ©fÃ©rences croisÃ©es
        lines = [
            "[2024-01-15 10:30:00] COMMANDE_RECU CMD_REF_001 client=CLI_001 articles=[ART_001]",
            "[2024-01-15 10:30:05] VALIDATION_COMMANDE CMD_REF_001 â†’ ordre=ORD_REF_001 status=VALIDE",
            "[2024-01-15 10:30:10] ORDRE_TRAITE ORD_REF_001 â†’ livraison=LIV_REF_001"
        ]
        
        try:
            all_success = True
            for line in lines:
                if not self.tracker.process_log_line(line):
                    all_success = False
            
            # VÃ©rifier que les rÃ©fÃ©rences croisÃ©es ont Ã©tÃ© crÃ©Ã©es
            details = self.tracker.get_flux_details("CMD_REF_001")
            has_cross_refs = details and len(details['cross_references']) > 0
            
            success = all_success and has_cross_refs
            details_msg = f"Tous logs traitÃ©s: {all_success}, RÃ©fÃ©rences trouvÃ©es: {has_cross_refs}"
            self.log_test("RÃ©fÃ©rences croisÃ©es", success, details_msg)
            
        except Exception as e:
            self.log_test("RÃ©fÃ©rences croisÃ©es", False, f"Erreur: {e}")
    
    def test_sub_flows(self):
        """Test des sous-flux"""
        print("\n=== Test des sous-flux ===")
        
        lines = [
            "[2024-01-15 10:30:00] COMMANDE_RECU CMD_SUB_001 client=CLI_001 articles=[ART_SUB_001, ART_SUB_002]",
            "[2024-01-15 10:30:02] CREATION_ARTICLES CMD_SUB_001 articles=[ART_SUB_001, ART_SUB_002]",
            "[2024-01-15 10:30:05] TRAITEMENT_ARTICLE ART_SUB_001 parent=CMD_SUB_001 stock=DISPONIBLE",
            "[2024-01-15 10:30:06] TRAITEMENT_ARTICLE ART_SUB_002 parent=CMD_SUB_001 stock=DISPONIBLE"
        ]
        
        try:
            all_success = True
            for line in lines:
                if not self.tracker.process_log_line(line):
                    all_success = False
            
            # VÃ©rifier que les sous-flux ont Ã©tÃ© crÃ©Ã©s
            details = self.tracker.get_flux_details("CMD_SUB_001")
            has_children = details and len(details['children']) > 0
            
            success = all_success and has_children
            details_msg = f"Tous logs traitÃ©s: {all_success}, Enfants trouvÃ©s: {has_children}"
            self.log_test("Sous-flux", success, details_msg)
            
        except Exception as e:
            self.log_test("Sous-flux", False, f"Erreur: {e}")
    
    def test_database_integrity(self):
        """Test de l'intÃ©gritÃ© de la base de donnÃ©es"""
        print("\n=== Test d'intÃ©gritÃ© DB ===")
        
        try:
            # VÃ©rifier que la DB existe et contient des donnÃ©es
            conn = sqlite3.connect('logs_flow.db')
            cursor = conn.cursor()
            
            # Compter les enregistrements dans chaque table
            tables = ['flux_types', 'applications', 'flux_instances', 'log_entries', 'cross_references']
            counts = {}
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                counts[table] = cursor.fetchone()[0]
            
            conn.close()
            
            # VÃ©rifier qu'il y a des donnÃ©es
            has_data = all(count > 0 for count in [counts['flux_types'], counts['applications'], counts['flux_instances']])
            
            details_msg = f"Compteurs: {counts}"
            self.log_test("IntÃ©gritÃ© base de donnÃ©es", has_data, details_msg)
            
        except Exception as e:
            self.log_test("IntÃ©gritÃ© base de donnÃ©es", False, f"Erreur: {e}")
    
    def test_performance(self):
        """Test de performance basique"""
        print("\n=== Test de performance ===")
        
        import time
        
        # Test avec 1000 lignes de log similaires
        start_time = time.time()
        
        try:
            count = 0
            for i in range(1000):
                line = f"[2024-01-15 10:30:{i%60:02d}] COMMANDE_RECU CMD_PERF_{i:03d} client=CLI_{i:03d} articles=[ART_{i:03d}]"
                if self.tracker.process_log_line(line):
                    count += 1
            
            end_time = time.time()
            duration = end_time - start_time
            rate = count / duration if duration > 0 else 0
            
            success = count > 0 and duration < 60  # Moins d'une minute pour 1000 logs
            details_msg = f"TraitÃ© {count}/1000 logs en {duration:.2f}s ({rate:.1f} logs/s)"
            self.log_test("Performance 1000 logs", success, details_msg)
            
        except Exception as e:
            self.log_test("Performance 1000 logs", False, f"Erreur: {e}")
    
    def run_all_tests(self):
        """Lance tous les tests"""
        print("ğŸš€ DÃ©but des tests de robustesse")
        print("=" * 50)
        
        # Supprimer l'ancienne DB pour repartir Ã  zÃ©ro
        if Path('logs_flow.db').exists():
            os.remove('logs_flow.db')
        
        # RÃ©initialiser le tracker
        self.tracker = LogFlowTracker()
        
        # Lancer tous les tests
        self.test_file_processing()
        self.test_json_processing()
        self.test_individual_lines()
        self.test_forced_application()
        self.test_cross_references()
        self.test_sub_flows()
        self.test_database_integrity()
        self.test_performance()
        
        # RÃ©sumÃ© final
        print("\n" + "=" * 50)
        print("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
        print("=" * 50)
        print(f"Total: {self.test_results['total_tests']}")
        print(f"âœ“ RÃ©ussis: {self.test_results['passed_tests']}")
        print(f"âœ— Ã‰checs: {self.test_results['failed_tests']}")
        
        if self.test_results['failed_tests'] > 0:
            print(f"ğŸ“‰ Taux de rÃ©ussite: {(self.test_results['passed_tests']/self.test_results['total_tests'])*100:.1f}%")
        else:
            print("ğŸ‰ Tous les tests ont rÃ©ussi !")
        
        return self.test_results['failed_tests'] == 0

def main():
    """Point d'entrÃ©e principal"""
    runner = TestRunner()
    success = runner.run_all_tests()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
