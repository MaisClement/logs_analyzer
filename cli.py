#!/usr/bin/env python3
"""
Utilitaire en ligne de commande pour le syst√®me de suivi de flux
"""

import argparse
import json
import sys
from pathlib import Path
from main import LogFlowTracker

def cmd_process_file(args):
    """Traite un fichier de logs"""
    tracker = LogFlowTracker(args.config)
    
    if not Path(args.file).exists():
        print(f"Erreur: Fichier {args.file} non trouv√©")
        return 1
    
    print(f"Traitement du fichier: {args.file}")
    stats = tracker.process_log_file(args.file)
    
    print(f"R√©sultats:")
    print(f"  - Lignes totales: {stats['total_lines']}")
    print(f"  - Lignes trait√©es: {stats['processed_lines']}")
    print(f"  - Lignes √©chou√©es: {stats['failed_lines']}")
    
    if stats['failed_lines'] > 0:
        print(f"  - Taux de succ√®s: {(stats['processed_lines']/stats['total_lines'])*100:.1f}%")
    
    return 0

def cmd_process_line(args):
    """Traite une ligne de log unique"""
    tracker = LogFlowTracker(args.config)
    
    success = tracker.process_log_line(
        args.line, 
        force_flux_type=getattr(args, 'flux_type', None),
        force_application=getattr(args, 'application', None)
    )
    
    if success:
        print("‚úì Ligne trait√©e avec succ√®s")
        return 0
    else:
        print("‚úó √âchec du traitement de la ligne")
        return 1

def cmd_get_flux(args):
    """R√©cup√®re les d√©tails d'un flux"""
    tracker = LogFlowTracker(args.config)
    
    # V√©rifier si des r√©f√©rences crois√©es existent pour ce flux
    details = tracker.get_flux_details(args.reference)
    if not details:
        print(f"Flux '{args.reference}' non trouv√©")
        return 1      # Si des r√©f√©rences crois√©es existent, r√©cup√©rer tous les flux li√©s
    has_cross_references = ((details.get('cross_references') and len(details['cross_references']) > 0) or 
                           (details.get('incoming_references') and len(details['incoming_references']) > 0))
    if has_cross_references:
        # Utiliser la nouvelle m√©thode pour r√©cup√©rer tous les flux li√©s
        linked_flows_data = tracker.get_all_linked_flows(args.reference)
        
        if args.json:
            print(json.dumps(linked_flows_data, indent=2, ensure_ascii=False))
        else:
            print(f"R√âF√âRENCES CROIS√âES D√âTECT√âES - Affichage de tous les flux li√©s")
            print("=" * 80)
            print(f"Flux initial demand√©: {args.reference}")
            print(f"Total des flux li√©s: {linked_flows_data['total_linked_flows']}")
            print()
            
            # Afficher le r√©sum√© des connexions
            cross_ref_map = linked_flows_data['cross_reference_map']
            if cross_ref_map['summary']['total_connections'] > 0:
                print(f"üìä R√©sum√© des connexions:")
                print(f"   ‚Ä¢ Total des connexions: {cross_ref_map['summary']['total_connections']}")
                if cross_ref_map['summary']['bidirectional_pairs']:
                    print(f"   ‚Ä¢ Paires bidirectionnelles: {len(cross_ref_map['summary']['bidirectional_pairs'])}")
                print()
            
            print("-" * 60)
              # Collecter tous les logs de tous les flux pour un affichage unifi√©
            all_logs = []
            main_flux_ref = None
            main_flux_data = None
            subflow_source = None
            requested_flux_data = None
              # Identifier le flux demand√© et collecter les informations
            for ref, flux_data in linked_flows_data['linked_flows'].items():
                subflow_info = flux_data.get('subflow_info', {})
                is_subflow = subflow_info.get('is_subflow', False)
                
                # Identifier si c'est le flux demand√© ou si la r√©f√©rence demand√©e est un sous-flux de ce flux
                flux_contains_requested = (ref == args.reference or 
                                         (is_subflow and subflow_info.get('requested_reference') == args.reference))
                
                if flux_contains_requested:
                    requested_flux_data = flux_data
                    if is_subflow and subflow_info.get('requested_reference') == args.reference:
                        subflow_source = subflow_info['parent_reference']
                    elif ref == args.reference and not is_subflow:
                        # Le flux demand√© est le flux principal lui-m√™me
                        requested_flux_data = flux_data
                
                # Chercher si args.reference est dans les enfants de ce flux
                children = flux_data.get('children', [])
                for child in children:
                    if child['reference'] == args.reference:
                        subflow_source = ref
                        # Cr√©er les infos du sous-flux pour l'affichage
                        if not requested_flux_data:
                            requested_flux_data = {
                                'subflow_info': {
                                    'is_subflow': True,
                                    'requested_reference': args.reference,
                                    'parent_reference': ref,
                                    'subflow_details': {
                                        'reference': child['reference'],
                                        'status': child['status']
                                    }
                                }
                            }
                        break
                
                # Identifier le flux principal de la cha√Æne (celui qui a des r√©f√©rences sortantes mais pas entrantes, ou le plus ancien)
                incoming_refs = flux_data.get('incoming_references', [])
                outgoing_refs = flux_data.get('outgoing_references', [])
                
                # Le flux principal est typiquement celui qui d√©marre la cha√Æne (pas de r√©f√©rences entrantes)
                if not main_flux_ref:
                    main_flux_ref = ref
                    main_flux_data = flux_data
                elif not incoming_refs and outgoing_refs:
                    # Flux qui g√©n√®re des r√©f√©rences mais n'en re√ßoit pas = flux principal
                    main_flux_ref = ref
                    main_flux_data = flux_data
                elif incoming_refs and not outgoing_refs and not main_flux_data.get('outgoing_references'):
                    # Si le flux actuel principal n'a pas de r√©f√©rences sortantes, prendre celui qui en a
                    continue
                
                # Ajouter les logs avec pr√©fixe de flux
                for log in flux_data['logs']:
                    log_with_prefix = log.copy()
                    log_with_prefix['flux_prefix'] = ref
                    all_logs.append(log_with_prefix)
            
            # Si on a une source de sous-flux, s'assurer que c'est bien le flux principal affich√©
            if subflow_source and subflow_source in linked_flows_data['linked_flows']:
                main_flux_ref = subflow_source
                main_flux_data = linked_flows_data['linked_flows'][subflow_source]            # Informations sur le sous-flux si applicable
            if subflow_source:
                print(f"‚ö†Ô∏è  Sous-flux de: {subflow_source}")
                print(f"üìÑ Affichage des informations parentes (flux principal)")
                print()
            
            # Informations principales du flux (parent ou principal de la cha√Æne)
            if main_flux_data:
                flux = main_flux_data['flux']
                print(f"Flux: {main_flux_ref}")
                print(f"Type: {flux['flux_type']}")
                print(f"Status: {flux['status']}")
                print(f"Cr√©√©: {flux['created_at']}")
                print(f"Modifi√©: {flux['updated_at']}")
                
                # Si c'est un sous-flux qui a √©t√© demand√©, afficher aussi ses d√©tails sp√©cifiques
                if subflow_source and requested_flux_data:
                    subflow_info = requested_flux_data.get('subflow_info', {})
                    if subflow_info.get('is_subflow'):
                        subflow_details = subflow_info.get('subflow_details', {})
                        print()
                        print(f"üîπ D√©tails du sous-flux demand√© ({args.reference}):")
                        print(f"   Status: {subflow_details.get('status', 'N/A')}")
                        print(f"   Cr√©√©: {subflow_details.get('created_at', 'N/A')}")
                        print(f"   Modifi√©: {subflow_details.get('updated_at', 'N/A')}")
                        
                        # Logs sp√©cifiques au sous-flux
                        subflow_logs = subflow_info.get('subflow_logs', [])
                        if subflow_logs:
                            print(f"   Logs sp√©cifiques: {len(subflow_logs)} entr√©es")
                
                print()
            
            # Affichage condens√© des logs avec pr√©fixe du flux
            if all_logs:
                print(f"Logs ({len(all_logs)} entr√©es):")
                # Trier les logs par timestamp
                all_logs.sort(key=lambda x: x['timestamp'])
                
                for j, log in enumerate(all_logs, 1):
                    print(f"[{log['flux_prefix']}]  {j}. [{log['timestamp']}] {log['application']}/{log['log_type']}")
                    print(f"[{log['flux_prefix']}]     {log['raw_log'][:80]}...")
                print()
            
            # R√©f√©rences sortantes consolid√©es
            all_outgoing_refs = []
            for ref, flux_data in linked_flows_data['linked_flows'].items():
                for ref_out in flux_data['outgoing_references']:
                    ref_info = f"  ‚Üí {ref_out['target_reference']} ({ref_out['reference_field']})"
                    if ref_info not in all_outgoing_refs:
                        all_outgoing_refs.append(ref_info)
            
            if all_outgoing_refs:
                print(f"R√©f√©rences sortantes ({len(all_outgoing_refs)}):")
                for ref_out in all_outgoing_refs:
                    print(ref_out)
                print()
            
            # Sous-flux consolid√©s (sans doublons)
            all_children = set()
            for ref, flux_data in linked_flows_data['linked_flows'].items():
                for child in flux_data['children']:
                    all_children.add(f"  - {child['reference']} ({child['status']})")
            
            if all_children:
                print(f"Sous-flux ({len(all_children)}):")
                for child in sorted(all_children):
                    print(child)
                print()
            
            # Afficher la carte des connexions
            if cross_ref_map['connections']:
                print("üó∫Ô∏è  CARTE DES CONNEXIONS:")
                print("-" * 40)
                for connection in cross_ref_map['connections']:
                    print(f"  {connection['source_reference']} ‚Üí {connection['target_reference']}")
                    print(f"    via {connection['reference_field']} = {connection['reference_value']}")
                print()
    
    else:
        # Pas de r√©f√©rences crois√©es, utiliser l'affichage standard
        if args.json:
            print(json.dumps(details, indent=2, ensure_ascii=False))
        else:
            # Afficher les informations sur le sous-flux si applicable
            subflow_info = details.get('subflow_info', {})
            is_subflow = subflow_info.get('is_subflow', False)
            
            if is_subflow:
                print(f"=== Sous-flux {args.reference} (flux parent: {subflow_info['parent_reference']}) ===")
                print("‚ö†Ô∏è  La r√©f√©rence demand√©e correspond √† un sous-flux.")
                print(f"üìÑ Affichage des d√©tails du flux parent: {subflow_info['parent_reference']}")
                print()
                
                # D√©tails du sous-flux sp√©cifique
                subflow_details = subflow_info['subflow_details']
                print(f"üîπ D√©tails du sous-flux {args.reference}:")
                print(f"   Status: {subflow_details['status']}")
                print(f"   Cr√©√©: {subflow_details['created_at']}")
                print(f"   Modifi√©: {subflow_details['updated_at']}")
                
                # Logs sp√©cifiques au sous-flux
                subflow_logs = subflow_info.get('subflow_logs', [])
                if subflow_logs:
                    print(f"\nüîπ Logs sp√©cifiques au sous-flux ({len(subflow_logs)} entr√©es):")
                    for i, log in enumerate(subflow_logs, 1):
                        print(f"   {i}. [{log['timestamp']}] {log['application']}/{log['log_type']}")
                        print(f"      {log['raw_log'][:80]}...")
                
                print("\n" + "="*60)
                print(f"üìã D√©tails complets du flux parent: {subflow_info['parent_reference']}")
                print("="*60)
            else:
                print(f"=== Flux {args.reference} ===")
            
            # Afficher les d√©tails du flux principal (parent si sous-flux, sinon le flux lui-m√™me)
            flux = details['flux']
            print(f"Type: {flux['flux_type']}")
            print(f"Status: {flux['status']}")
            print(f"Cr√©√©: {flux['created_at']}")
            print(f"Modifi√©: {flux['updated_at']}")
            
            print(f"\nLogs du flux principal ({len(details['logs'])} entr√©es):")
            for i, log in enumerate(details['logs'], 1):
                print(f"  {i}. [{log['timestamp']}] {log['application']}/{log['log_type']}")
                print(f"     {log['raw_log'][:80]}...")
            
            if details['cross_references']:
                print(f"\nR√©f√©rences crois√©es ({len(details['cross_references'])}):")
                for ref in details['cross_references']:
                    print(f"  ‚Üí {ref['target_reference']} ({ref['reference_field']})")
            
            if details['children']:
                print(f"\nSous-flux ({len(details['children'])}):")
                for child in details['children']:
                    # Marquer le sous-flux demand√© s'il fait partie des enfants
                    marker = " ‚Üê (demand√©)" if is_subflow and child['reference'] == args.reference else ""
                    print(f"  - {child['reference']} ({child['status']}){marker}")
    
    return 0

def cmd_process_json(args):
    """Traite des logs au format JSON"""
    tracker = LogFlowTracker(args.config)
    
    if args.file:
        with open(args.file, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
    else:
        json_data = json.loads(sys.stdin.read())
    
    print("Traitement des logs JSON...")
    stats = tracker.process_json_logs(json_data)
    
    print(f"R√©sultats:")
    print(f"  - Entr√©es totales: {stats['total_entries']}")
    print(f"  - Entr√©es trait√©es: {stats['processed_entries']}")
    print(f"  - Entr√©es √©chou√©es: {stats['failed_entries']}")
    
    return 0

def cmd_parse_test(args):
    """Teste le parsing d'une ligne sans l'enregistrer"""
    tracker = LogFlowTracker(args.config)
    
    parsed = tracker.parse_log_line(
        args.line,
        force_flux_type=getattr(args, 'flux_type', None),
        force_application=getattr(args, 'application', None)
    )
    
    if parsed:
        print("‚úì Ligne pars√©e avec succ√®s:")
        print(f"  Flux: {parsed.flux_type}")
        print(f"  Application: {parsed.application}")
        print(f"  Type: {parsed.log_type}")
        print(f"  Timestamp: {parsed.timestamp}")
        print(f"  Identifiants: {parsed.identifier_fields}")
        print(f"  Payload: {parsed.payload_fields}")
        if parsed.reference_links:
            print(f"  R√©f√©rences: {parsed.reference_links}")
    else:
        print("‚úó Impossible de parser la ligne")
        return 1
    
    return 0

def cmd_list_config(args):
    """Liste les flux types et applications disponibles"""
    tracker = LogFlowTracker(args.config)
    
    print("=== Configuration des flux disponibles ===\n")
    
    for flux_name, flux_patterns in tracker.patterns.items():
        print(f"üìã Flux: {flux_name}")
        flux_config = tracker.config['flux_types'][flux_name]
        print(f"   Description: {flux_config.get('description', 'N/A')}")
        print(f"   Applications:")
        
        for app_name, app_patterns in flux_patterns.items():
            print(f"     ‚Ä¢ {app_name}")
            log_types = list(app_patterns.keys())
            print(f"       Types de logs: {', '.join(log_types)}")
        
        print()  # Ligne vide entre les flux
    
    return 0

def cmd_incomplete_flows(args):
    """Analyse les flux incomplets"""
    tracker = LogFlowTracker(args.config)
    
    # R√©cup√©rer les flux incomplets
    incomplete_flows = tracker.get_incomplete_flows(max_age_hours=getattr(args, 'max_age_hours', None))
    
    if not incomplete_flows:
        print("‚úÖ Aucun flux incomplet trouv√© !")
        return 0
    
    if args.json:
        print(json.dumps(incomplete_flows, indent=2, ensure_ascii=False))
        return 0
    
    # Affichage format√©
    total_incomplete = sum(len(instances) for instances in incomplete_flows.values())
    print(f"üîç Analyse des flux incomplets - {total_incomplete} flux d√©tect√©s")
    print("=" * 60)
    
    for flux_type, instances in incomplete_flows.items():
        print(f"\nüìã {flux_type} ({len(instances)} flux incomplets)")
        print("-" * 40)
        
        for i, instance in enumerate(instances, 1):
            # Ic√¥ne selon l'√¢ge
            if instance['age_hours'] > 24:
                age_icon = "üö®"  # Tr√®s ancien
            elif instance['age_hours'] > 8:
                age_icon = "‚ö†Ô∏è"   # Ancien
            else:
                age_icon = "üïê"  # R√©cent
            
            print(f"{i:2d}. {age_icon} {instance['reference']}")
            print(f"     √Çge: {instance['age_hours']}h | Compl√©tion: {instance['completion_rate']}%")
            print(f"     Status: {instance['status']}")
            
            if instance['last_activity']:
                print(f"     Derni√®re activit√©: {instance['last_activity'][:19]} ({instance['last_log_type']})")
            
            if instance['missing_stages']:
                missing_str = ", ".join(instance['missing_stages'])
                print(f"     ‚ùå √âtapes manquantes: {missing_str}")
            
            if instance['present_stages']:
                present_str = ", ".join(instance['present_stages'])
                print(f"     ‚úÖ √âtapes pr√©sentes: {present_str}")
            
            if instance['children_count'] > 0:
                print(f"     üë• Sous-flux: {instance['children_count']}")
            
            print()
    
    # Statistiques globales
    print("=" * 60)
    print("üìä STATISTIQUES GLOBALES")
    print("=" * 60)
    
    # Compter par type d'√©tape manquante
    missing_stages_count = {}
    total_age = 0
    oldest_flux = None
    
    for flux_type, instances in incomplete_flows.items():
        for instance in instances:
            total_age += instance['age_hours']
            
            if not oldest_flux or instance['age_hours'] > oldest_flux['age_hours']:
                oldest_flux = instance
            
            for missing_stage in instance['missing_stages']:
                missing_stages_count[missing_stage] = missing_stages_count.get(missing_stage, 0) + 1
    
    if total_incomplete > 0:
        avg_age = total_age / total_incomplete
        print(f"√Çge moyen des flux incomplets: {avg_age:.1f}h")
        
        if oldest_flux:
            print(f"Flux le plus ancien: {oldest_flux['reference']} ({oldest_flux['age_hours']}h)")
        
        print("\n√âtapes les plus souvent manquantes:")
        for stage, count in sorted(missing_stages_count.items(), key=lambda x: x[1], reverse=True):
            print(f"  ‚Ä¢ {stage}: {count} fois")
    
    return 0

def cmd_stats(args):
    """Affiche les statistiques des flux par √©tapes"""
    tracker = LogFlowTracker(args.config)
    
    # R√©cup√©rer les statistiques avec ou sans d√©tails
    include_details = getattr(args, 'details', False)
    stats = tracker.get_stats(include_details=include_details)
    
    if args.json:
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        return 0
    
    # Affichage format√©
    print("üìä STATISTIQUES DES FLUX")
    print("=" * 60)
    
    # Vue d'ensemble
    print(f"Total des flux: {stats['total_flux']}")
    if stats['database_overview']['total_subflows'] > 0:
        main_flux_count = stats['total_flux'] - stats['database_overview']['total_subflows']
        print(f"  ‚Ä¢ Flux principaux: {main_flux_count}")
        print(f"  ‚Ä¢ Sous-flux: {stats['database_overview']['total_subflows']}")
    
    print(f"Total des entr√©es de log: {stats['database_overview']['total_log_entries']}")
    print(f"Total des r√©f√©rences crois√©es: {stats['database_overview']['total_cross_references']}")
    print()
    
    # Flux par type
    if stats['flux_by_type']:
        print("üìã FLUX PAR TYPE")
        print("-" * 40)
        for flux_type, info in stats['flux_by_type'].items():
            print(f"{flux_type}: {info['count']} flux")
            if info['description']:
                print(f"  ‚îî‚îÄ {info['description']}")
        print()
    
    # Flux par statut
    if stats['flux_by_status']:
        print("üîÑ FLUX PAR STATUT")
        print("-" * 40)
        for status, count in stats['flux_by_status'].items():
            print(f"{status}: {count} flux")
        print()
    
    # Analyse des √©tapes par type de flux
    if stats['stages_analysis']:
        print("üéØ ANALYSE DES √âTAPES PAR TYPE DE FLUX")
        print("-" * 40)
        
        for flux_type, analysis in stats['stages_analysis'].items():
            print(f"\nüìä {flux_type} ({analysis['total_flux']} flux)")
            print("‚îÄ" * 30)
            
            # √âtapes requises
            if analysis['required_stages']:
                print("  √âtapes requises:")
                for stage in analysis['required_stages']:
                    if stage in analysis['stages']:
                        stage_info = analysis['stages'][stage]
                        print(f"    ‚úÖ {stage}: {stage_info['count']}/{analysis['total_flux']} ({stage_info['percentage']}%)")
                    else:
                        print(f"    ‚ùå {stage}: 0/{analysis['total_flux']} (0%)")
            
            # √âtapes optionnelles pr√©sentes
            optional_present = [stage for stage in analysis['stages'].keys() if stage in analysis['optional_stages']]
            if optional_present:
                print("  √âtapes optionnelles pr√©sentes:")
                for stage in optional_present:
                    stage_info = analysis['stages'][stage]
                    print(f"    üîπ {stage}: {stage_info['count']}/{analysis['total_flux']} ({stage_info['percentage']}%)")
            
            # Autres √©tapes observ√©es
            other_stages = [stage for stage in analysis['stages'].keys() 
                          if stage not in analysis['required_stages'] and stage not in analysis['optional_stages']]
            if other_stages:
                print("  Autres √©tapes observ√©es:")
                for stage in other_stages:
                    stage_info = analysis['stages'][stage]
                    print(f"    üìù {stage}: {stage_info['count']}/{analysis['total_flux']} ({stage_info['percentage']}%)")
    
    # Statistiques globales des √©tapes
    if stats['global_stage_counts']:
        print(f"\nüåê √âTAPES LES PLUS UTILIS√âES (tous types confondus)")
        print("-" * 40)
        
        # Trier par nombre d'occurrences
        sorted_stages = sorted(stats['global_stage_counts'].items(), key=lambda x: x[1], reverse=True)
        
        for stage, count in sorted_stages[:10]:  # Top 10
            print(f"  {stage}: {count} occurrences")
    
    # Statistiques sur les relations
    print(f"\nüîó RELATIONS ENTRE FLUX")
    print("-" * 40)
    print(f"Flux avec r√©f√©rences crois√©es: {stats['flux_with_cross_references']}")
    print(f"Flux avec sous-flux: {stats['flux_with_subflows']}")
    
    if stats['total_flux'] > 0:
        cross_ref_percentage = (stats['flux_with_cross_references'] / stats['total_flux']) * 100
        subflow_percentage = (stats['flux_with_subflows'] / stats['total_flux']) * 100
        print(f"  ‚Ä¢ {cross_ref_percentage:.1f}% des flux ont des r√©f√©rences crois√©es")
        print(f"  ‚Ä¢ {subflow_percentage:.1f}% des flux ont des sous-flux")
    
    return 0

def main():
    parser = argparse.ArgumentParser(description='Utilitaire de suivi de flux multi-applicatifs')
    parser.add_argument('--config', '-c', default='config.yaml', 
                       help='Fichier de configuration (d√©faut: config.yaml)')
    
    subparsers = parser.add_subparsers(dest='command', help='Commandes disponibles')
    
    # Commande process-file
    parser_file = subparsers.add_parser('process-file', help='Traite un fichier de logs')
    parser_file.add_argument('file', help='Chemin vers le fichier de logs')
    parser_file.set_defaults(func=cmd_process_file)
      # Commande process-line
    parser_line = subparsers.add_parser('process-line', help='Traite une ligne de log')
    parser_line.add_argument('line', help='Ligne de log √† traiter')
    parser_line.add_argument('--flux-type', '-f', help='Forcer un type de flux sp√©cifique')
    parser_line.add_argument('--application', '-a', help='Forcer une application sp√©cifique')
    parser_line.set_defaults(func=cmd_process_line)
    
    # Commande get-flux
    parser_flux = subparsers.add_parser('get-flux', help='R√©cup√®re les d√©tails d\'un flux')
    parser_flux.add_argument('reference', help='R√©f√©rence du flux')
    parser_flux.add_argument('--json', action='store_true', help='Sortie en format JSON')
    parser_flux.set_defaults(func=cmd_get_flux)
    
    # Commande process-json
    parser_json = subparsers.add_parser('process-json', help='Traite des logs JSON')
    parser_json.add_argument('--file', '-f', help='Fichier JSON (sinon lecture depuis stdin)')
    parser_json.set_defaults(func=cmd_process_json)
      # Commande parse-test
    parser_test = subparsers.add_parser('parse-test', help='Teste le parsing d\'une ligne')
    parser_test.add_argument('line', help='Ligne de log √† tester')
    parser_test.add_argument('--flux-type', '-f', help='Forcer un type de flux sp√©cifique')
    parser_test.add_argument('--application', '-a', help='Forcer une application sp√©cifique')
    parser_test.set_defaults(func=cmd_parse_test)
    
    # Commande list-config
    parser_list = subparsers.add_parser('list-config', help='Liste les flux et applications disponibles')
    parser_list.set_defaults(func=cmd_list_config)
      # Commande incomplete-flows
    parser_incomplete = subparsers.add_parser('incomplete-flows', help='Analyse les flux incomplets')
    parser_incomplete.add_argument('--max-age-hours', type=int, help='√Çge maximum des flux √† consid√©rer (en heures)')
    parser_incomplete.add_argument('--json', action='store_true', help='Sortie en format JSON')
    parser_incomplete.set_defaults(func=cmd_incomplete_flows)    # Commande stats
    parser_stats = subparsers.add_parser('stats', help='Affiche les statistiques des flux par √©tapes')
    parser_stats.add_argument('--json', action='store_true', help='Sortie en format JSON')
    parser_stats.add_argument('--details', action='store_true', help='Inclut la liste des flux pour chaque √©tape (format JSON uniquement)')
    parser_stats.set_defaults(func=cmd_stats)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
    
    try:
        return args.func(args)
    except Exception as e:
        print(f"Erreur: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
